<html lang="en">

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GQMLYQNJ60"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-GQMLYQNJ60');
    </script>
    <script>
        var attempts = 0; 
        var max_trys = 3;
        function checkPassword() {
            if (attempts >= max_trys){
                alert("You are banned.");
                return false;
            }
            var password = prompt("Please enter the password:");
            if (password === "jason01") {
                window.location.href = "private_exps.html";
            } else {
                attempts++;
                alert("Incorrect password. Access denied. Attempts remaining: " + (max_trys - attempts));
                if (attempts >= max_trys) {
                    alert("You have exceeded the maximum number of attempts. Your IP address has be sent to the server YanchengCai. Attempting to access your camera.");
                    alert("Camera Access failed.");
                }
            }
            return false;
        }
    </script>

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="author" content="Yancheng Cai">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css"
        integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
    <!-- <link rel="stylesheet" href="css/menu.css"> -->
    <!-- Custom styles for this template -->
    <link href="files/jumbotron.css" rel="stylesheet">
    <!-- <link rel="icon" href="images/Cambridge.jpeg"> -->
    <link rel="shortcut icon" href="https://www.cam.ac.uk/sites/www.cam.ac.uk/themes/fresh/favicon.ico"
        type="image/vnd.microsoft.icon">
    <!-- <script src="js/main.js"></script>
    <script src="js/scroll.js"></script> -->
    <title>Yancheng Cai</title>
</head>



<body>
    <div class="container">
        <h3 id="Home" style="padding-top: 80px; margin-top: -80px;"></h3>
    </div>
    <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark" id="Home">
        <div class="container">
            <a class="navbar-brand" href="#Home">Yancheng Cai - 蔡彦成</a>

            <div class="collapse navbar-collapse" id="navbarToggle">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="#Home">Home</a>
                    </li>
                    <!-- <li class="nav-item">
                        <a class="nav-link" href="#Talks">Talks</a>
                    </li> -->
                    <li class="nav-item">
                        <a class="nav-link" href="#Publications">Publications</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="academic_chinese.html">中文版页面</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="life.html">My Life</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#" onclick="return checkPassword()">Private Zone</a>
                    </li>
                    <!-- <li class="nav-item">
                        <a class="nav-link" href="#Research Experience">Research Experience</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#Course Projects and Competition">Course Projects and Competition</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#Award">Award</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#Academic_Service">Academic Service</a>
                    </li> -->
                </ul>
            </div>
        </div>
    </nav>

    <div class="container" style="padding-top: 80px; font-size: 17px">
        <div class="row">
            <div class="col-md-3" ,="" style="padding-right: 10px">
                <br>
                <img class="img-responsive img-rounded" src="images/my_image_5.jpg" alt="Photo"
                    style="max-width: 100%; border:1px solid black">
            </div>

            <div class="col-md-9">
                <br>
                <p> I am currently a second-year Ph.D. student in Computer Science and Technology at the University of
                    Cambridge, under the supervision of Prof. <a href="https://www.cl.cam.ac.uk/~rkm38/"
                        target="_blank">Rafal Mantiuk</a>. I recently obtained my Bachelor of
                    Engineering degree from <a href="https://www.fudan.edu.cn/en/" target="_blank"> Fudan University
                    </a> in 2023. In 2022, I had the opportunity to work as a research assistant at Stanford University
                    - <a href="https://svl.stanford.edu/" target="_blank"> SVL </a>,
                    advised by Prof. <a href="https://jiajunwu.com/" target="_blank">Jiajun Wu</a> and Prof. <a
                        href="https://yunzhuli.github.io/" target="_blank">Yunzhu Li</a>. Prior to that, I
                    served as a research assistant at Fudan University from 2021 to 2023, under the guidance of Prof.
                    <a href="http://www.it.fudan.edu.cn/En/Data/View/3012" target="_blank">Tao Chen</a>.
                </p>

                <p> I am highly interested in the fields of computer vision, robotics, and computer graphics.
                    Specifically, throughout my doctoral studies, I intend to concentrate on the realm of Display Image
                    Quality Assessment. My objective is to integrate insights from the human visual system with
                    cutting-edge machine learning techniques, thereby establishing robust computational models for the
                    evaluation of display image and video quality.
                </p>

                <p>
                    Email: yc613 [at] cam [dot] ac [dot] uk & cycxueshu [at] 163 [dot] com<br>
                    Wechat: cyc13700232963 <br>
                    <a href="https://openreview.net/profile?id=~Yancheng_Cai1" target="_blank">OpenReview</a> /
                    <a href="https://github.com/caiyancheng" target="_blank"> GitHub</a> /
                    <a href="https://www.zhihu.com/people/cai-yan-cheng-23g" target="_blank"> 知乎Zhihu</a> /
                    <!-- <a href="https://twitter.com/YanchengCai" target="_blank"> Twitter</a> -->
                    <br>
                </p>

                <p>

                </p>

            </div>
        </div>
    </div><br>

    <!-- News -->
    <div class="container">
        <h3 id="News" style="padding-top: 80px; margin-top: -80px;">News</h3>
        <ul>
            <!--
			<li>
				<font color="firebrick">[Upcoming]</font> Invited Talk at <b>Carnegie Mellon University</b>.
			</li>
			-->
            <li> <b>[2024/07]</b>: A first-authored paper has been accepted by ACM SIGGRAPH Asia 2024.
            <li> <b>[2024/06]</b>: Invited talk at University of Cambridge Selwyn College.
            <li> <b>[2023/08]</b>: A first-authored paper has been accepted by IEEE Transaction on Image Processing.
            <li> <b>[2023/07]</b>: Invited talk at TechBeat platform.
            <li> <b>[2023/02]</b>: A co-first-authored paper has been accepted by CVPR2023.
            <li> <b>[2023/02]</b>: A co-first-authored paper has been accepted by Neurocomputing.
            <li> <b>[2021/09]</b>: A co-authored paper was accepted by ICONIP2021.
            <li> <b>[2021/07]</b>: A co-authored paper was accepted by PRCV2021.
            <li> <b>[2020/12]</b>: I am honored to be a three-star member of <a
                    href="http://www.shenghan.org/CAIYANCHENG" target="_blank"> Shenghan High IQ Club </a>.
        </ul>
    </div><br><br>


    <!-- Education -->
    <div class="container">
        <h3 id="Education" stype="padding-top: 80px; margin-top: -80px;">
            Education
        </h3>

        <hr>

        <div class="row">
            <div class="col-md-2">
                <a href="https://www.cam.ac.uk/" target="_blank"><img class="img-fluid img-rounded"
                        src="images/Cambridge.jpeg" alt=""></a>
            </div>

            <div class="col-md-10">
                <b>
                    <font color="black">University of Cambridge</font>
                </b>
                <br>
                Department of Computer Science and Technology<br>
                Ph.D. Student<br><br>
                October 2023 - Present
            </div>
        </div>
        <hr>

        <div class="row">
            <div class="col-md-2">
                <a href="https://www.stanford.edu/" target="_blank"><img class="img-fluid img-rounded"
                        src="images/stanford_university.jpg" alt=""></a>
            </div>

            <div class="col-md-10">
                <b>
                    <font color="black">Stanford University</font>
                </b>
                <br>
                Computer Science Department<br>
                Non-degree Undergraduate Student<br>
                On-site Research Intern <a
                    href="https://bechtel.stanford.edu/departments/f-1-and-j-1-students/undergraduate-visiting-research-interns-uvri"
                    target="_blank">
                    (<b>UVRI Intern</b>) </a><br><br>
                January 2022 - June 2023
            </div>
        </div>
        <hr>

        <div class="row">
            <div class="col-md-2">
                <a href="https://www.fudan.edu.cn/en/" target="_blank"><img class="img-fluid img-rounded"
                        src="images/fudan_university.jpg" alt=""></a>
            </div>

            <div class="col-md-10">
                <b>
                    <font color="black">Fudan University</font>
                </b>
                <br>
                <!-- No. 220, Handan Road, Yangpu District, Shanghai, People's Republic of China<br> -->
                Intelligent Science and Technology (excellent class)<br>
                Undergraduate Student<br>
                <b>GPA</b>: 3.92/4.0; <b>Ranking</b>: 1/245<br><br>
                September 2019 - June 2023
            </div>
        </div>
        <hr>
    </div><br><br>



    <!-- Publications -->
    <div class="container">
        <h3 id="Publications" style="padding-top: 80px; margin-top: -80px;">
            Publications
        </h3>

        <div id="pubs">
            <font color="black">(* indicates equal contribution)</font><br>
            <hr>
            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/elaTCSF_plot_2.jpg" alt="">
                </div>
                <div class="col-md-9">
                    <a href="https://caiyancheng.github.io/academic.html"><b>Yancheng Cai</b></a>,
                    <a href="https://www.ntnu.edu/employees/ali.bozorgian">Ali Bozorgian</a>,
                    <a href="https://malihaashraf.github.io/">Maliha Ashraf</a>,
                    <a href="https://www.linkedin.com/in/robert-wanat-0816a090">Robert Wanat</a>,
                    <a href="https://www.cl.cam.ac.uk/~rkm38/">Rafał K. Mantiuk</a>
                    <br>
                    <b>
                        <font color="black">elaTCSF: A Temporal Contrast Sensitivity Function for Flicker Detection and Modeling Variable Refresh Rate Flicker
                        </font>
                    </b><br>
                    <b><a href="https://asia.siggraph.org/2024/" target="_blank">SIGGRAPH Asia 2024</a></b>, Accepted (With Strong Accept)<br>
                </div>
            </div>

            <hr>
            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/paper_1.jpg" alt="">
                </div>
                <div class="col-md-9">
                    <a href="https://caiyancheng.github.io/" target="_blank"><b>Yancheng Cai</b></a>*,
                    <a href="https://s-tian.github.io/" target="_blank">Stephen Tian</a>*,
                    <a href="https://kovenyu.com/" target="_blank">Hong-Xing Yu</a>,
                    <a href="https://zakharos.github.io/" target="_blank">Sergey Zakharov</a>,
                    <a href="https://www.thekatherineliu.com/" target="_blank">Katherine Liu</a>,
                    <a href="https://adriengaidon.com/" target="_blank">Adrien Gaidon</a>,
                    <a href="https://yunzhuli.github.io/" target="_blank">Yunzhu Li</a>,
                    <a href="https://jiajunwu.com/" target="_blank">Jiajun Wu</a>
                    <br>
                    <b>
                        <font color="black">Multi-object manipulation via object-centric neural scattering functions
                        </font>
                    </b><br>
                    <b><a href="https://cvpr2023.thecvf.com/" target="_blank">CVPR 2023</a></b>, Published (With two
                    Strong Accepts)<br>
                    <a href="https://s-tian.github.io/projects/actionosf/" ,="" target="_blank">
                        <small>[Project]</small></a>
                    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_Multi-Object_Manipulation_via_Object-Centric_Neural_Scattering_Functions_CVPR_2023_paper.pdf"
                        ,="" target="_blank"> <small>[Paper]</small></a>
                    <!-- <a href="projects/comp_nerf_dy/comp_nerf_dy.bib" target="_blank"> <small>[OpenReview]</small></a><br> -->
                </div>
            </div>

            <hr>
            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/paper_2.jpg" alt="">
                </div>
                <div class="col-md-9">
                    <a href="https://caiyancheng.github.io/" target="_blank"><b>Yancheng Cai</b></a>,
                    <a href="https://openreview.net/profile?id=~Bo_Zhang17" target="_blank">Bo Zhang</a>,
                    <a href="https://scholar.google.com/citations?user=OOY-4CwAAAAJ&hl=en" target="_blank">Baopu Li</a>,
                    <a href="http://www.it.fudan.edu.cn/En/Data/View/3012" target="_blank">Tao Chen</a>,
                    <a href="https://scholar.google.com/citations?user=Obo7-bIAAAAJ&hl=en" target="_blank">Hongliang
                        Yan</a>,
                    <a href="https://openreview.net/profile?id=~Jingdong_Zhang2" target="_blank">Jingdong Zhang</a>,
                    Jiahao Xu
                    <br>
                    <b>
                        <font color="black">Rethinking Cross-Domain Pedestrian Detection: A Background-Focused
                            Distribution Alignment Framework for Instance-free One-Stage Detectors
                        </font>
                    </b><br>
                    <b><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83" target="_blank">TIP (IEEE
                            Transactions on Image Processing)</a></b>, Published<br>
                    <a href="https://ieeexplore.ieee.org/document/10231122" target="_blank">
                        <small>[IEEE paper]</small></a>
                    <a href="https://zhuanlan.zhihu.com/p/652557366" target="_blank">
                        <small>[知乎]</small></a><br>
                    <!-- <a href="projects/comp_nerf_dy/comp_nerf_dy.bib" target="_blank"> <small>[OpenReview]</small></a><br> -->
                </div>
            </div>
            <hr>

            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/paper_6.jpg" alt="">
                </div>
                <div class="col-md-9">
                    Lei Lu*,
                    <a href="https://caiyancheng.github.io/" target="_blank"><b>Yancheng Cai</b></a>*,
                    Hua Huang,
                    Ping Wang
                    <br>
                    <b>
                        <font color="black">An efficient fine-grained vehicle recognition method based on part-level
                            feature
                            optimization
                        </font>
                    </b><br>
                    <b><a href="https://dl.acm.org/journal/neuroc" target="_blank">Neurocomputing</a></b>, Published
                    <a href="https://www.sciencedirect.com/science/article/pii/S0925231223002643" target="_blank">
                        <small>[paper]</small></a>
                    <!-- <a href="projects/comp_nerf_dy/comp_nerf_dy.bib" target="_blank"> <small>[OpenReview]</small></a><br> -->
                </div>
            </div>
            <hr>

            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/paper_3.jpg" alt="">
                </div>
                <div class="col-md-9">
                    <a href="https://openreview.net/profile?id=~Jingdong_Zhang2" target="_blank">Jingdong Zhang</a>,
                    <a href="https://scholar.google.com/citations?user=UEZZP5QAAAAJ&hl=en&oi=sra" target="_blank">Peng
                        Ye</a>,
                    <a href="https://openreview.net/profile?id=~Bo_Zhang17" target="_blank">Bo Zhang</a>,
                    Hancheng Ye,
                    <a href="https://scholar.google.com/citations?user=OOY-4CwAAAAJ&hl=en" target="_blank">Baopu Li</a>,
                    <a href="https://caiyancheng.github.io/" target="_blank"><b>Yancheng Cai</b></a>,
                    <a href="http://www.it.fudan.edu.cn/En/Data/View/3012" target="_blank">Tao Chen</a>
                    <br>
                    <b>
                        <font color="black">Enhancing Task-Related Features Learning with Task Agnostic-to-Specific
                            Attention for Multi-task Dense Prediction
                        </font>
                    </b><br>
                    <b><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI (IEEE
                            Transactions on Pattern Analysis and Machine Intelligence)</a></b>, Under Review
                    <!-- <a href="projects/comp_nerf_dy/comp_nerf_dy.bib" target="_blank"> <small>[OpenReview]</small></a><br> -->
                </div>
            </div>
            <hr>

            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/paper_4.jpg" alt="">
                </div>
                <div class="col-md-9">
                    Zhaoqing Wu,
                    <a href="https://caiyancheng.github.io/" target="_blank"><b>Yancheng Cai</b></a>,
                    Xiaohua Qiu, Min Li, Yujie He, Yu Song, Weidong Du
                    <br>
                    <b>
                        <font color="black">Dual-band Maritime Ship Classification based on Multi-layer Convolutional
                            Features and Bayesian Decision
                        </font>
                    </b><br>
                    <b><a href="http://www.wikicfp.com/cfp/servlet/event.showcfp?eventid=118925&copyownerid=13149"
                            target="_blank">ICONIP 2021 (International Conference on Neural Information Processing
                            2021)</a></b>, Published <br>
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-92185-9_36" target="_blank">
                        <small>[Springer]</small></a><br>
                </div>
            </div>
            <hr>

            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/paper_5.jpg" alt="">
                </div>
                <div class="col-md-9">
                    YuJie He, Min Li, ZhenHua Wei,
                    <a href="https://caiyancheng.github.io/" target="_blank"><b>Yancheng Cai</b></a>
                    <br>
                    <b>
                        <font color="black">Infrared Small Target Detection Based on Weighted Variation Coefficient
                            Local Contrast Measure
                        </font>
                    </b><br>
                    <b><a href="http://2021.prcv.cn/index_en.html" target="_blank">PRCV 2021 (Chinese Conference on
                            Pattern Recognition and Computer Vision 2021)</a></b>, Published <br>
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-88010-1_10" target="_blank">
                        <small>[Springer]</small></a><br>
                </div>
            </div>
            <hr>

        </div>
    </div>


    <!-- Research Experience -->
    <div class="container">
        <h3 id="Research Experience" style="padding-top: 80px; margin-top: -80px;">Research Experience</h3>
        <ul>
            <li>
                January 2022 - June 2023, Research Assistant, Stanford Vision and Learning Lab<br>
                Advisors: Prof. <a href="https://jiajunwu.com/" target="_blank">Jiajun Wu</a>, Prof. <a
                    href="https://yunzhuli.github.io/" target="_blank">Yunzhu Li</a>.
            </li>
            <li>
                October 2020 - June 2023, Research Assistant, Fudan Embedded Deep Learning and Visual Analysis Lab<br>
                Advisors: Prof. <a href="http://www.it.fudan.edu.cn/En/Data/View/3012" target="_blank">Tao Chen</a>.
            </li>
            <!-- <li>
                January 2021 - November 2021, Research Assistant, Xi'an Research Institute<br>
                Advisors: Prof. Min Li.
            </li> -->
        </ul>
    </div><br><br>


    <!-- Award -->
    <div class="container">
        <h3 id="Award" style="padding-top: 80px; margin-top: -80px;">Selected Award</h3>
        <ul>
            <li>2022 China National Scholarship (The <b>highest</b> honorable national scholarship to Chinese students).
                (0.2%)</li>
            <li>2020 China National Scholarship (The <b>highest</b> honorable national scholarship to Chinese students).
                (0.2%)</li>
            <li>6th place in the China Finals of the Advanced Driver Assistance Systems Competition (ADAS) held by Dell.
            </li>
            <li>Top Ten Students in School of Information Science and Technology, Fudan University. (1%)</li>
            <li>Fudan University Individual Award for Scientific Research. (0.5%)</li>
        </ul>
    </div><br><br>


    <!-- Academic Service -->
    <div class="container">
        <h3 id="Academic_Service" style="padding-top: 80px; margin-top: -80px;">Academic Service</h3>
        <ul>
            <li>Journal Reviewer: <b>T-PAMI</b></li>
            <li>Conference Reviewer: <b>CVPR 2023, CVPR 2022, ECCV 2022</b></li>
        </ul>
    </div><br>

    <div class="container">
        <hr>
        <center>
            <footer>
                <p>© Yancheng Cai 2023</p>
            </footer>
        </center>
    </div>
    <!-- /container -->

    <!-- Bootstrap core JavaScript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script>showPubs(1);</script>
    <script>var scroll = new SmoothScroll('a[href*="#"]', { speed: 1000 });</script>
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js"
        integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4"
        crossorigin="anonymous"></script>
</body>

</html>