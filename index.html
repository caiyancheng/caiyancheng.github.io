<html lang="en">

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-111713571-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'UA-111713571-1');
    </script>

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css"
        integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
    <!-- Custom styles for this template -->
    <link href="files/jumbotron.css" rel="stylesheet">
    <script src="js/main.js"></script>
    <script src="js/scroll.js"></script>
    <title>Yancheng Cai</title>
</head>



<body>
    <div class="container">
        <h3 id="Home" style="padding-top: 80px; margin-top: -80px;"></h3>
    </div>
    <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark" id="Home">
        <div class="container">
            <a class="navbar-brand" href="#Home">Yancheng Cai (蔡彦成)</a>

            <div class="collapse navbar-collapse" id="navbarToggle">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="#Home">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#Publications">Publications</a>
                    </li>
                    <!-- <li class="nav-item">
                        <a class="nav-link" href="#Research Experience">Research Experience</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#Course Projects and Competition">Course Projects and Competition</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#Award">Award</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#Academic_Service">Academic Service</a>
                    </li> -->
                </ul>
            </div>
        </div>
    </nav>

    <div class="container" style="padding-top: 80px; font-size: 17px">
        <div class="row">
            <div class="col-md-3" ,="" style="padding-right: 40px">
                <br>
                <img class="img-responsive img-rounded" src="images/my_image_3.jpg" alt="Photo"
                    style="max-width: 100%; border:1px solid black">
            </div>

            <div class="col-md-9">
                <br>
                <p> I am currently an undergraduate student majoring in Intelligent Science and Technology (Excellence
                    Class) at <a href="https://www.fudan.edu.cn/en/" target="_blank"> Fudan University </a>. I am
                    currently a senior and expect to receive the Bachelor of Engineering degree in June 2023. I'm now
                    working as a
                    research intern (UGVR) at Stanford University - <a href="https://svl.stanford.edu/" target="_blank">
                        Stanford Vision and Learning Lab </a>, advised by Prof. <a href="https://jiajunwu.com/"
                        target="_blank">Jiajun Wu</a> and Prof. <a href="https://yunzhuli.github.io/"
                        target="_blank">Yunzhu Li</a>. I also work as an Research Assistant at Fudan University, advised
                    by Prof. <a href="http://www.it.fudan.edu.cn/En/Data/View/3012" target="_blank">Tao Chen</a>.
                </p>

                <p> My research interests lie in computer vision, robotics, and computer graphics. In particular, I
                    want to find underlying, domain-invariant general representations for various computer vision
                    tasks, which can be learned from directly obtained visual observations and fundamentally overcome
                    the influence of drastic changes in irrelevant factors.
                </p>

                <p>
                    Email: 19307140030@fudan.edu.cn & yccai@stanford.edu <br>
                    Wechat: cyc13700232963 <br>
                    <a href="https://openreview.net/profile?id=~Yancheng_Cai1" target="_blank">OpenReview</a> /
                    <a href="https://github.com/caiyancheng" target="_blank">GitHub</a> <br>

                    I am currently dealing with the final exams, sorry if the reply is slow.
                </p>

            </div>
        </div>
    </div><br>


    <!-- News -->
    <div class="container">
        <h3 id="News" style="padding-top: 80px; margin-top: -80px;">News</h3>
        <ul>
            <!--
			<li>
				<font color="firebrick">[Upcoming]</font> Invited Talk at <b>Carnegie Mellon University</b>.
			</li>
			-->
            <li> <b>December 2022</b>: I am actively applying for a Ph.D. in 2023 Fall! My dream is to become a baseline
                level scholar in the future.
            <li> <b>December 2022</b>: I earned a 3.92/4.0 GPA in my first three academic years. I ranked first (1/245)
                in the School of
                Information Science and Technology of Fudan University for three consecutive academic years.
            <li> <b>December 2020</b>: I am honored to be a three-star member of <a
                    href="http://www.shenghan.org/CAIYANCHENG" target="_blank"> Shenghan High IQ Club </a>.
        </ul>
    </div><br><br>


    <!-- Education -->
    <div class="container">
        <h3 id="Education" stype="padding-top: 80px; margin-top: -80px;">
            Education
        </h3>

        <hr>
        <div class="row">
            <div class="col-md-2">
                <a href="https://www.fudan.edu.cn/en/" target="_blank"><img class="img-fluid img-rounded"
                        src="images/stanford_university.jpg" alt=""></a>
            </div>

            <div class="col-md-10">
                <b>
                    <font color="black">Stanford University</font>
                </b>
                <br>
                Computer Science Department<br>
                Non-degree Undergraduate Student<br>
                On-site Research Intern <a
                    href="https://engineering.stanford.edu/students-academics/programs/global-engineering-programs/chinese-ugvr"
                    target="_blank">
                    (<b>UGVR Intern</b>) </a><br><br>
                January 2022 - Present
            </div>
        </div>
        <hr>

        <div class="row">
            <div class="col-md-2">
                <a href="https://www.fudan.edu.cn/en/" target="_blank"><img class="img-fluid img-rounded"
                        src="images/fudan_university.jpg" alt=""></a>
            </div>

            <div class="col-md-10">
                <b>
                    <font color="black">Fudan University</font>
                </b>
                <br>
                <!-- No. 220, Handan Road, Yangpu District, Shanghai, People's Republic of China<br> -->
                Intelligent Science and Technology (excellent class)<br>
                Undergraduate Student<br>
                <b>GPA</b>: 3.92/4.0; <b>Ranking</b>: 1/245<br><br>
                September 2019 - Present
            </div>
        </div>
        <hr>
    </div><br><br>



    <!-- Publications -->
    <div class="container">
        <h3 id="Publications" style="padding-top: 80px; margin-top: -80px;">
            Publications
        </h3>

        <div id="pubs">
            <font color="black">(* indicates equal contribution)</font><br>
            <hr>

            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/paper_1.jpg" alt="">
                </div>
                <div class="col-md-9">
                    <a href="https://caiyancheng.github.io/" target="_blank"><b>Yancheng Cai</b></a>*,
                    <a href="https://s-tian.github.io/" target="_blank">Stephen Tian</a>*,
                    <a href="https://kovenyu.com/" target="_blank">Hong-Xing Yu</a>,
                    <a href="https://zakharos.github.io/" target="_blank">Sergey Zakharov</a>,
                    <a href="https://www.katherineliu.me/" target="_blank">Katherine Liu</a>,
                    <a href="https://adriengaidon.com/" target="_blank">Adrien Gaidon</a>,
                    <a href="https://yunzhuli.github.io/" target="_blank">Yunzhu Li</a>,
                    <a href="https://jiajunwu.com/" target="_blank">Jiajun Wu</a>
                    <br>
                    <b>
                        <font color="black">Neural Implicit Scattering Functions for Inverse Parameter Estimation and
                            Dynamics Modeling of Multi-Object Interactions
                        </font>
                    </b><br>
                    <b><a href="https://cvpr2023.thecvf.com/" target="_blank">CVPR 2023</a></b>, Under Review
                    <!-- <a href="projects/comp_nerf_dy/comp_nerf_dy.bib" target="_blank"> <small>[OpenReview]</small></a><br> -->
                </div>
            </div>

            <hr>
            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/paper_2.jpg" alt="">
                </div>
                <div class="col-md-9">
                    <a href="https://caiyancheng.github.io/" target="_blank"><b>Yancheng Cai</b></a>,
                    <a href="https://github.com/BOBrown/" target="_blank">Bo Zhang</a>,
                    <a href="https://scholar.google.com/citations?user=OOY-4CwAAAAJ&hl=en" target="_blank">Baopu Li</a>,
                    <a href="http://www.it.fudan.edu.cn/En/Data/View/3012" target="_blank">Tao Chen</a>,
                    <a href="https://scholar.google.com/citations?user=Obo7-bIAAAAJ&hl=en" target="_blank">Hongliang
                        Yan</a>,
                    <a href="https://openreview.net/profile?id=~Jingdong_Zhang2" target="_blank">Jingdong Zhang</a>,
                    Jiahao Xu
                    <br>
                    <b>
                        <font color="black">Rethinking Cross-Domain Pedestrian Detection: A Background-Focused
                            Distribution Alignment Framework for One-Stage Detectors
                        </font>
                    </b><br>
                    <b><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83" target="_blank">TIP (IEEE
                            Transactions on Image Processing)</a></b>, Under Review
                    <!-- <a href="projects/comp_nerf_dy/comp_nerf_dy.bib" target="_blank"> <small>[OpenReview]</small></a><br> -->
                </div>
            </div>
            <hr>

            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/paper_3.jpg" alt="">
                </div>
                <div class="col-md-9">
                    <a href="https://openreview.net/profile?id=~Jingdong_Zhang2" target="_blank">Jingdong Zhang</a>,
                    <a href="https://scholar.google.com/citations?user=UEZZP5QAAAAJ&hl=en&oi=sra" target="_blank">Peng
                        Ye</a>,
                    <a href="https://github.com/BOBrown/" target="_blank">Bo Zhang</a>,
                    Hancheng Ye,
                    <a href="https://scholar.google.com/citations?user=OOY-4CwAAAAJ&hl=en" target="_blank">Baopu Li</a>,
                    <a href="https://caiyancheng.github.io/" target="_blank"><b>Yancheng Cai</b></a>,
                    <a href="http://www.it.fudan.edu.cn/En/Data/View/3012" target="_blank">Tao Chen</a>
                    <br>
                    <b>
                        <font color="black">Enhancing Task-Related Features Learning with Task Agnostic-to-Specific
                            Attention for Multi-task Dense Prediction
                        </font>
                    </b><br>
                    <b><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI (IEEE
                            Transactions on Pattern Analysis and Machine Intelligence)</a></b>, Under Review
                    <!-- <a href="projects/comp_nerf_dy/comp_nerf_dy.bib" target="_blank"> <small>[OpenReview]</small></a><br> -->
                </div>
            </div>
            <hr>

            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/paper_4.jpg" alt="">
                </div>
                <div class="col-md-9">
                    Zhaoqing Wu,
                    <a href="https://caiyancheng.github.io/" target="_blank"><b>Yancheng Cai</b></a>,
                    Xiaohua Qiu, Min Li, Yujie He, Yu Song, Weidong Du
                    <br>
                    <b>
                        <font color="black">Dual-band Maritime Ship Classification based on Multi-layer Convolutional
                            Features and Bayesian Decision
                        </font>
                    </b><br>
                    <b><a href="http://www.wikicfp.com/cfp/servlet/event.showcfp?eventid=118925&copyownerid=13149"
                            target="_blank">ICONIP 2021 (International Conference on Neural Information Processing
                            2021)</a></b>, Published <br>
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-92185-9_36" target="_blank">
                        <small>[Springer]</small></a><br>
                </div>
            </div>
            <hr>

            <div class="row">
                <div class="col-md-3">
                    <img class="img-fluid img-rounded" src="images/paper_5.jpg" alt="">
                </div>
                <div class="col-md-9">
                    YuJie He, Min Li, ZhenHua Wei,
                    <a href="https://caiyancheng.github.io/" target="_blank"><b>Yancheng Cai</b></a>
                    <br>
                    <b>
                        <font color="black">Infrared Small Target Detection Based on Weighted Variation Coefficient
                            Local Contrast Measure
                        </font>
                    </b><br>
                    <b><a href="http://2021.prcv.cn/index_en.html" target="_blank">PRCV 2021 (Chinese Conference on
                            Pattern Recognition and Computer Vision 2021)</a></b>, Published <br>
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-88010-1_10" target="_blank">
                        <small>[Springer]</small></a><br>
                </div>
            </div>
            <hr>

        </div>
    </div>


    <!-- Research Experience -->
    <div class="container">
        <h3 id="Research Experience" style="padding-top: 80px; margin-top: -80px;">Research Experience</h3>
        <ul>
            <li>
                January 2022 - Present, Research Assistant, Stanford Vision and Learning Lab<br>
                Advisors: Prof. <a href="https://jiajunwu.com/" target="_blank">Jiajun Wu</a>, Prof. <a
                    href="https://yunzhuli.github.io/" target="_blank">Yunzhu Li</a>.
            </li>
            <li>
                October 2020 - Present, Research Assistant, Fudan Embedded Deep Learning and Visual Analysis Lab<br>
                Advisors: Prof. <a href="http://www.it.fudan.edu.cn/En/Data/View/3012" target="_blank">Tao Chen</a>.
            </li>
            <li>
                January 2021 - November 2021, Research Assistant, Xi'an Research Institute<br>
                Advisors: Prof. Min Li.
            </li>
        </ul>
    </div><br><br>


    <!-- Award -->
    <div class="container">
        <h3 id="Award" style="padding-top: 80px; margin-top: -80px;">Selected Award</h3>
        <ul>
            <li>2022 China National Scholarship (The <b>highest</b> honorable national scholarship to Chinese students).
                (0.2%)</li>
            <li>2020 China National Scholarship (The <b>highest</b> honorable national scholarship to Chinese students).
                (0.2%)</li>
            <li>6th place in the China Finals of the Autonomous Car Competition (ADAS) held by Dell.</li>
            <li>Top Ten Students in School of Information Science and Technology, Fudan University. (1%)</li>
            <li>Fudan University Individual Award for Scientific Research. (0.5%)</li>
        </ul>
    </div><br><br>


    <!-- Academic Service -->
    <div class="container">
        <h3 id="Academic_Service" style="padding-top: 80px; margin-top: -80px;">Academic Service</h3>
        <ul>
            <li>Reviewer/ Emergency Reviewer in <b>CVPR 2023</b></li>
            <li>Reviewer/ Emergency Reviewer in <b>CVPR 2022</b></li>
            <li>Reviewer in <b>ECCV 2022</b></li>
        </ul>
    </div><br>

    <div class="container">
        <hr>
        <center>
            <footer>
                <p>© Yancheng Cai 2022</p>
            </footer>
        </center>
    </div>
    <!-- /container -->

    <!-- Bootstrap core JavaScript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script>showPubs(1);</script>
    <script>var scroll = new SmoothScroll('a[href*="#"]', { speed: 1000 });</script>
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js"
        integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4"
        crossorigin="anonymous"></script>
</body>

</html>